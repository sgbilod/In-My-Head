# AI Engine Service - Environment Configuration

# Database
DATABASE_URL=postgresql://inmyhead:inmyhead_dev_pass@localhost:5434/inmyhead_dev

# Qdrant Vector Database
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_DOCUMENTS=document_embeddings
QDRANT_COLLECTION_CHUNKS=chunk_embeddings
QDRANT_COLLECTION_QUERIES=query_embeddings

# AI Models
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384
MAX_CHUNK_SIZE=500
CHUNK_OVERLAP=50

# LLM Providers (Optional - for RAG generation)
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
COHERE_API_KEY=

# Local LLM Settings
USE_LOCAL_LLM=true
LOCAL_LLM_MODEL=llama2
LOCAL_LLM_URL=http://localhost:11434

# RAG Configuration
RAG_TOP_K=5
RAG_SIMILARITY_THRESHOLD=0.7
RAG_MAX_CONTEXT_LENGTH=4000
RAG_TEMPERATURE=0.7

# Service Configuration
SERVICE_NAME=ai-engine
SERVICE_PORT=8000
LOG_LEVEL=INFO
