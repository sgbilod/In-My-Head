"""
Vector storage integration demo.

This example demonstrates how to use the vector storage system
to store embeddings and perform semantic search.

Prerequisites:
- Qdrant service running on localhost:6333
- OpenAI API key configured
- Redis service running
"""

import os
import sys
import asyncio
from typing import List

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))

# pylint: disable=wrong-import-position
from vector_storage import (
    VectorStore,
    VectorDocument,
    SearchFilter,
)
from embeddings import (
    EmbeddingGenerator,
    EmbeddingCache,
    BatchEmbeddingProcessor,
)
# pylint: enable=wrong-import-position


# ============================================================================
# DEMO: Basic Vector Storage Operations
# ============================================================================


def demo_basic_operations():
    """Demonstrate basic vector storage operations."""
    print("\n" + "=" * 70)
    print("DEMO 1: Basic Vector Storage Operations")
    print("=" * 70)

    # Initialize store
    store = VectorStore(
        host="localhost",
        port=6333,
        default_collection="demo_documents",
        vector_size=1536,
    )

    # Setup collection
    print("\n1. Setting up collection...")
    store.setup(recreate=True)
    print("✓ Collection created")

    # Sample embeddings (normally generated by embedding model)
    sample_vectors = [
        [0.1] * 1536,
        [0.2] * 1536,
        [0.3] * 1536,
    ]

    # Create documents
    documents = [
        VectorDocument(
            vector=sample_vectors[0],
            payload={
                "text": "Python is a high-level programming language.",
                "title": "Python Basics",
                "category": "programming",
                "language": "python",
            },
        ),
        VectorDocument(
            vector=sample_vectors[1],
            payload={
                "text": "Machine learning is a subset of AI.",
                "title": "ML Introduction",
                "category": "ai",
                "language": "python",
            },
        ),
        VectorDocument(
            vector=sample_vectors[2],
            payload={
                "text": "Docker containers provide isolation.",
                "title": "Docker Guide",
                "category": "devops",
                "language": "bash",
            },
        ),
    ]

    # Insert documents
    print("\n2. Inserting documents...")
    store.insert_batch(documents)
    print(f"✓ Inserted {len(documents)} documents")

    # Semantic search
    print("\n3. Performing semantic search...")
    results = store.semantic_search(
        query_vector=sample_vectors[0],
        limit=3,
    )
    print(f"✓ Found {len(results)} results:")
    for i, result in enumerate(results, 1):
        print(f"   {i}. {result.payload['title']} (score: {result.score:.3f})")

    # Keyword search with filters
    print("\n4. Performing hybrid search (vector + filters)...")
    filters = [
        SearchFilter(field="category", value="ai", operator="match")
    ]
    results = store.hybrid_search(
        query_vector=sample_vectors[1],
        filters=filters,
        limit=3,
    )
    print(f"✓ Found {len(results)} AI-related results:")
    for i, result in enumerate(results, 1):
        print(f"   {i}. {result.payload['title']} (score: {result.score:.3f})")

    # Count documents
    print("\n5. Counting documents...")
    total = store.count()
    print(f"✓ Total documents: {total}")

    # Get statistics
    print("\n6. Getting statistics...")
    stats = store.get_stats()
    print(f"✓ Statistics:")
    print(f"   - Total uploaded: {stats['total_uploaded']}")
    print(f"   - Total searched: {stats['total_searched']}")
    print(f"   - Failed uploads: {stats['failed_uploads']}")

    # Cleanup
    print("\n7. Cleaning up...")
    store.delete_collection("demo_documents")
    store.close()
    print("✓ Collection deleted and connection closed")


# ============================================================================
# DEMO: Integration with Embedding Generation
# ============================================================================


async def demo_full_pipeline():
    """Demonstrate full pipeline: text → embeddings → vector storage."""
    print("\n" + "=" * 70)
    print("DEMO 2: Full Pipeline (Text → Embeddings → Vector Storage)")
    print("=" * 70)

    # Sample texts
    texts = [
        "Python is a versatile programming language used for web development.",
        "Machine learning models can recognize patterns in data.",
        "Docker containers provide lightweight application isolation.",
        "FastAPI is a modern web framework for building APIs.",
        "Embeddings are vector representations of text.",
    ]

    print(f"\n1. Processing {len(texts)} text documents...")

    # Initialize components
    generator = EmbeddingGenerator()
    cache = EmbeddingCache()
    processor = BatchEmbeddingProcessor(
        generator=generator,
        cache=cache,
    )

    store = VectorStore(
        host="localhost",
        port=6333,
        default_collection="demo_full_pipeline",
    )

    # Setup collection
    store.setup(recreate=True)
    print("✓ Collection ready")

    # Generate embeddings
    print("\n2. Generating embeddings...")
    embeddings = await processor.process_batch(texts)
    print(f"✓ Generated {len(embeddings)} embeddings")

    # Create vector documents
    documents = [
        VectorDocument(
            vector=emb.vector,
            payload={
                "text": text,
                "token_count": emb.token_count,
                "model": emb.model,
            },
        )
        for text, emb in zip(texts, embeddings)
    ]

    # Store in vector database
    print("\n3. Storing embeddings in Qdrant...")
    store.insert_batch(documents)
    print(f"✓ Stored {len(documents)} embeddings")

    # Search for similar documents
    print("\n4. Searching for similar documents...")
    query_text = "Tell me about programming languages"
    print(f"   Query: \"{query_text}\"")

    # Generate query embedding
    query_embedding = await generator.generate(query_text)

    # Search
    results = store.semantic_search(
        query_vector=query_embedding.vector,
        limit=3,
        score_threshold=0.5,
    )

    print(f"\n✓ Found {len(results)} similar documents:")
    for i, result in enumerate(results, 1):
        text_preview = result.payload["text"][:60] + "..."
        print(f"   {i}. Score: {result.score:.3f}")
        print(f"      Text: {text_preview}")

    # Get statistics
    print("\n5. Final statistics...")
    stats = store.get_stats()
    print(f"✓ Total operations:")
    print(f"   - Documents uploaded: {stats['total_uploaded']}")
    print(f"   - Searches performed: {stats['total_searched']}")

    # Cleanup
    print("\n6. Cleaning up...")
    store.delete_collection("demo_full_pipeline")
    store.close()
    await cache.close()
    print("✓ All resources cleaned up")


# ============================================================================
# DEMO: Advanced Search Features
# ============================================================================


def demo_advanced_search():
    """Demonstrate advanced search features."""
    print("\n" + "=" * 70)
    print("DEMO 3: Advanced Search Features")
    print("=" * 70)

    # Initialize store
    store = VectorStore(
        host="localhost",
        port=6333,
        default_collection="demo_advanced",
    )

    # Setup collection
    print("\n1. Setting up collection with sample data...")
    store.setup(recreate=True)

    # Create sample data with metadata
    sample_vectors = [[0.1 + i * 0.1] * 1536 for i in range(10)]

    documents = [
        VectorDocument(
            vector=sample_vectors[i],
            payload={
                "text": f"Document {i + 1}",
                "title": f"Title {i + 1}",
                "category": "tech" if i % 2 == 0 else "science",
                "year": 2020 + i,
                "views": 100 * (i + 1),
                "published": True if i > 5 else False,
            },
        )
        for i in range(10)
    ]

    store.insert_batch(documents)
    print(f"✓ Inserted {len(documents)} documents")

    # Filter by exact match
    print("\n2. Filter by category (exact match)...")
    filters = [SearchFilter(field="category", value="tech", operator="match")]
    results = store.hybrid_search(
        query_vector=sample_vectors[0],
        filters=filters,
        limit=5,
    )
    print(f"✓ Found {len(results)} tech documents")

    # Filter by range
    print("\n3. Filter by year range (2022-2024)...")
    filters = [
        SearchFilter(
            field="year",
            value={"gte": 2022, "lte": 2024},
            operator="range",
        )
    ]
    results = store.hybrid_search(
        query_vector=sample_vectors[0],
        filters=filters,
        limit=10,
    )
    print(f"✓ Found {len(results)} documents from 2022-2024:")
    for result in results:
        print(f"   - {result.payload['title']} ({result.payload['year']})")

    # Multiple filters
    print("\n4. Multiple filters (tech + published)...")
    filters = [
        SearchFilter(field="category", value="tech", operator="match"),
        SearchFilter(field="published", value=True, operator="match"),
    ]
    results = store.hybrid_search(
        query_vector=sample_vectors[0],
        filters=filters,
        limit=10,
    )
    print(f"✓ Found {len(results)} published tech documents")

    # Score threshold
    print("\n5. Semantic search with score threshold...")
    results = store.semantic_search(
        query_vector=sample_vectors[0],
        limit=10,
        score_threshold=0.8,
    )
    print(f"✓ Found {len(results)} high-confidence matches (>0.8)")

    # Cleanup
    print("\n6. Cleaning up...")
    store.delete_collection("demo_advanced")
    store.close()
    print("✓ Done")


# ============================================================================
# MAIN
# ============================================================================


def main():
    """Run all demos."""
    print("\n" + "=" * 70)
    print("VECTOR STORAGE INTEGRATION DEMO")
    print("=" * 70)

    try:
        # Demo 1: Basic operations
        demo_basic_operations()

        # Demo 2: Full pipeline (async)
        asyncio.run(demo_full_pipeline())

        # Demo 3: Advanced search
        demo_advanced_search()

        print("\n" + "=" * 70)
        print("ALL DEMOS COMPLETED SUCCESSFULLY! ✨")
        print("=" * 70 + "\n")

    except Exception as e:
        print(f"\n❌ Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
